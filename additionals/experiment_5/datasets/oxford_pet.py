# Gen Al Usage Statement:
# General architecture was designed and planned manually
# Gen AI was used to help with debugging refactoring and refining the architecture in depth
# Gen AI used: Claude, ChatGPT and Co-Pilot

# Extra library Usage: We used more than three pip installs but this code was for the experiment and these extra libraries are not used for the final implementation of weakly supervised segmentation framework

import torch
from torch.utils.data import Dataset
from torchvision.datasets import OxfordIIITPet

class OxfordPetClassification(Dataset):
    """
    Dataset wrapper for Oxford-IIIT Pet dataset that provides only image-level labels (pet breeds).
    Used for training the classifier in the weakly supervised learning pipeline.
    """
    def __init__(self, root, split='trainval', transform=None):
        """
        Args:
            root (str): Root directory where the dataset exists or will be downloaded
            split (str): Dataset split, either 'trainval' or 'test'
            transform (callable, optional): Optional transform to be applied on images
        """
        self.dataset = OxfordIIITPet(root, split=split, download=True)
        self.transform = transform
        
    def __len__(self):
        return len(self.dataset)
        
    def __getitem__(self, idx):
        img, target = self.dataset[idx]
        if self.transform:
            img = self.transform(img)
        # We'll use class IDs directly (0-36 for the 37 breeds)
        return {"image": img, "label": target}


class OxfordPetSegmentation(Dataset):
    """
    Dataset wrapper for Oxford-IIIT Pet dataset that provides both images and segmentation masks.
    Used for evaluation in the weakly supervised learning pipeline.
    """
    def __init__(self, root, split='test', transform_img=None, transform_mask=None):
        """
        Args:
            root (str): Root directory where the dataset exists or will be downloaded
            split (str): Dataset split, either 'trainval' or 'test'
            transform_img (callable, optional): Optional transform to be applied on images
            transform_mask (callable, optional): Optional transform to be applied on masks
        """
        self.dataset = OxfordIIITPet(root, split=split, target_types='segmentation', download=True)
        self.transform_img = transform_img
        self.transform_mask = transform_mask
        
    def __len__(self):
        return len(self.dataset)
        
    def __getitem__(self, idx):
        img, mask = self.dataset[idx]
        
        # Get the actual class label by creating a separate category-only dataset
        # This ensures we get the correct breed label for each image
        category_dataset = OxfordIIITPet(
            root=self.dataset.root, 
            split=self.dataset._split, 
            target_types="category",
            download=False
        )
        _, class_target = category_dataset[idx]
        
        if self.transform_img:
            img = self.transform_img(img)
        if self.transform_mask:
            mask = self.transform_mask(mask).squeeze(0)
            mask = mask.long()
            # Convert the trinary mask to binary (foreground vs background)
            # 1 = pet, 2 = boundary, 3 = background, 255 = ignore
            binary_mask = torch.zeros_like(mask)
            binary_mask[mask == 1] = 1  # Pet
            binary_mask[mask == 2] = 1  # Include boundary with pet
            # Background remains 0
            
        return {"image": img, "mask": binary_mask, "label": class_target}


class PseudoLabeledDataset(Dataset):
    """
    Dataset wrapper for data with pseudo-masks generated using GradCAM.
    Used for training the segmentation model in the weakly supervised learning pipeline.
    """
    def __init__(self, pseudo_labeled_data):
        """
        Args:
            pseudo_labeled_data (list): List of dictionaries containing 'image', 'pseudo_mask', and 'true_class'
                                       as generated by the GradCAM process
        """
        self.data = pseudo_labeled_data
        
    def __len__(self):
        return len(self.data)
        
    def __getitem__(self, idx):
        return {
            "image": self.data[idx]["image"].squeeze(0),
            "mask": self.data[idx]["pseudo_mask"].squeeze(0).squeeze(0),
            "label": self.data[idx]["true_class"]
        }