=== Weakly Supervised Segmentation Pipeline - 2025-04-20 03:41:23.153758 ===

[2025-04-20 03:41:23] Starting weakly supervised segmentation pipeline...
[2025-04-20 03:41:23] Device: cpu
[2025-04-20 03:41:23] PyTorch version: 2.6.0+cpu
[2025-04-20 03:41:23] 
1. Setting up classification datasets...
[2025-04-20 03:41:23] Training set (classification): 2944 images
[2025-04-20 03:41:23] Validation set (classification): 736 images
[2025-04-20 03:41:23] Test set (segmentation): 3669 images
[2025-04-20 03:41:23] 
2. Training the classifier...
[2025-04-20 03:41:23] Dropout Probability Value: 0.1
[2025-04-20 03:42:28]   Batch 0/184: Loss: 3.6235, Acc: 12.50%
[2025-04-20 03:42:28]     Sample 0: True=10, Pred=27
[2025-04-20 03:42:28]     Sample 1: True=24, Pred=23
[2025-04-20 03:49:50]   Batch 18/184: Loss: 3.4784, Acc: 0.00%
[2025-04-20 03:57:00]   Batch 36/184: Loss: 3.8355, Acc: 6.25%
[2025-04-20 04:04:29]   Batch 54/184: Loss: 3.8507, Acc: 0.00%
[2025-04-20 04:11:54]   Batch 72/184: Loss: 4.0756, Acc: 0.00%
[2025-04-20 04:19:14]   Batch 90/184: Loss: 3.7189, Acc: 0.00%
[2025-04-20 04:19:14]     Sample 0: True=25, Pred=35
[2025-04-20 04:19:14]     Sample 1: True=27, Pred=33
[2025-04-20 04:26:33]   Batch 108/184: Loss: 3.5351, Acc: 0.00%
[2025-04-20 04:34:07]   Batch 126/184: Loss: 3.4386, Acc: 6.25%
[2025-04-20 04:41:37]   Batch 144/184: Loss: 3.6939, Acc: 0.00%
[2025-04-20 04:49:02]   Batch 162/184: Loss: 3.7698, Acc: 0.00%
[2025-04-20 04:56:31]   Batch 180/184: Loss: 3.8270, Acc: 0.00%
[2025-04-20 04:56:31]     Sample 0: True=35, Pred=32
[2025-04-20 04:56:31]     Sample 1: True=32, Pred=33
[2025-04-20 05:03:06] Epoch [1/4], Train Loss: 3.7723, Train Acc: 3.02%, Val Acc: 2.17%
[2025-04-20 05:04:21]   Batch 0/184: Loss: 3.7257, Acc: 0.00%
[2025-04-20 05:04:22]     Sample 0: True=26, Pred=18
[2025-04-20 05:04:22]     Sample 1: True=23, Pred=32
[2025-04-20 05:11:23]   Batch 18/184: Loss: 3.5959, Acc: 0.00%
[2025-04-20 05:18:27]   Batch 36/184: Loss: 3.6499, Acc: 0.00%
[2025-04-20 05:25:26]   Batch 54/184: Loss: 3.6775, Acc: 0.00%
[2025-04-20 05:32:27]   Batch 72/184: Loss: 3.8225, Acc: 0.00%
[2025-04-20 05:39:29]   Batch 90/184: Loss: 3.8147, Acc: 0.00%
[2025-04-20 05:39:29]     Sample 0: True=28, Pred=20
[2025-04-20 05:39:29]     Sample 1: True=8, Pred=15
[2025-04-20 05:46:31]   Batch 108/184: Loss: 3.6705, Acc: 6.25%
[2025-04-20 05:53:36]   Batch 126/184: Loss: 3.6672, Acc: 0.00%
[2025-04-20 06:00:36]   Batch 144/184: Loss: 3.6569, Acc: 6.25%
[2025-04-20 06:07:35]   Batch 162/184: Loss: 3.8425, Acc: 0.00%
[2025-04-20 06:14:33]   Batch 180/184: Loss: 4.0159, Acc: 0.00%
[2025-04-20 06:14:33]     Sample 0: True=8, Pred=20
[2025-04-20 06:14:33]     Sample 1: True=7, Pred=28
[2025-04-20 06:21:03] Epoch [2/4], Train Loss: 3.7348, Train Acc: 2.31%, Val Acc: 2.17%
[2025-04-20 06:22:11]   Batch 0/184: Loss: 3.8347, Acc: 0.00%
[2025-04-20 06:22:11]     Sample 0: True=32, Pred=7
[2025-04-20 06:22:11]     Sample 1: True=27, Pred=33
[2025-04-20 06:29:12]   Batch 18/184: Loss: 3.7278, Acc: 6.25%
[2025-04-20 06:36:09]   Batch 36/184: Loss: 3.5785, Acc: 12.50%
[2025-04-20 06:43:09]   Batch 54/184: Loss: 3.6691, Acc: 0.00%
[2025-04-20 06:50:24]   Batch 72/184: Loss: 3.6594, Acc: 0.00%
[2025-04-20 06:57:20]   Batch 90/184: Loss: 3.8465, Acc: 0.00%
[2025-04-20 06:57:20]     Sample 0: True=20, Pred=13
[2025-04-20 06:57:20]     Sample 1: True=18, Pred=28
[2025-04-20 07:04:17]   Batch 108/184: Loss: 3.6190, Acc: 12.50%
[2025-04-20 07:11:15]   Batch 126/184: Loss: 3.5224, Acc: 0.00%
[2025-04-20 07:18:09]   Batch 144/184: Loss: 3.7087, Acc: 0.00%
[2025-04-20 07:25:06]   Batch 162/184: Loss: 3.7646, Acc: 6.25%
[2025-04-20 07:32:04]   Batch 180/184: Loss: 3.5674, Acc: 0.00%
[2025-04-20 07:32:04]     Sample 0: True=13, Pred=6
[2025-04-20 07:32:04]     Sample 1: True=18, Pred=20
[2025-04-20 07:38:34] Epoch [3/4], Train Loss: 3.6994, Train Acc: 2.85%, Val Acc: 2.58%
[2025-04-20 07:39:48]   Batch 0/184: Loss: 3.6344, Acc: 0.00%
[2025-04-20 07:39:49]     Sample 0: True=23, Pred=8
[2025-04-20 07:39:49]     Sample 1: True=12, Pred=33
[2025-04-20 07:46:42]   Batch 18/184: Loss: 3.7441, Acc: 0.00%
[2025-04-20 07:53:44]   Batch 36/184: Loss: 3.6789, Acc: 6.25%
[2025-04-20 08:00:41]   Batch 54/184: Loss: 3.6662, Acc: 18.75%
[2025-04-20 08:07:34]   Batch 72/184: Loss: 3.7551, Acc: 0.00%
[2025-04-20 08:14:37]   Batch 90/184: Loss: 3.8035, Acc: 0.00%
[2025-04-20 08:14:37]     Sample 0: True=5, Pred=34
[2025-04-20 08:14:37]     Sample 1: True=19, Pred=24
[2025-04-20 08:21:35]   Batch 108/184: Loss: 3.9162, Acc: 0.00%
[2025-04-20 08:28:35]   Batch 126/184: Loss: 3.8356, Acc: 6.25%
[2025-04-20 08:35:38]   Batch 144/184: Loss: 3.7737, Acc: 6.25%
[2025-04-20 08:42:35]   Batch 162/184: Loss: 3.7896, Acc: 0.00%
[2025-04-20 08:49:36]   Batch 180/184: Loss: 3.7529, Acc: 0.00%
[2025-04-20 08:49:36]     Sample 0: True=17, Pred=32
[2025-04-20 08:49:36]     Sample 1: True=28, Pred=8
[2025-04-20 08:56:07] Epoch [4/4], Train Loss: 3.6836, Train Acc: 3.16%, Val Acc: 1.77%
[2025-04-20 08:56:07] Validation Accuracy = 2.58%
[2025-04-20 08:56:07] Dropout Probability Value: 0.2
[2025-04-20 08:57:13]   Batch 0/184: Loss: 3.8388, Acc: 0.00%
[2025-04-20 08:57:13]     Sample 0: True=21, Pred=8
[2025-04-20 08:57:13]     Sample 1: True=12, Pred=34
[2025-04-20 09:04:15]   Batch 18/184: Loss: 4.1099, Acc: 6.25%
[2025-04-20 09:11:11]   Batch 36/184: Loss: 3.9311, Acc: 12.50%
[2025-04-20 09:18:04]   Batch 54/184: Loss: 3.7694, Acc: 0.00%
[2025-04-20 09:25:02]   Batch 72/184: Loss: 3.5448, Acc: 6.25%
[2025-04-20 09:32:07]   Batch 90/184: Loss: 3.8986, Acc: 18.75%
[2025-04-20 09:32:07]     Sample 0: True=5, Pred=33
[2025-04-20 09:32:07]     Sample 1: True=1, Pred=15
[2025-04-20 09:39:04]   Batch 108/184: Loss: 3.8881, Acc: 0.00%
[2025-04-20 09:46:07]   Batch 126/184: Loss: 3.9478, Acc: 6.25%
[2025-04-20 09:53:40]   Batch 144/184: Loss: 3.7959, Acc: 0.00%
[2025-04-20 10:01:11]   Batch 162/184: Loss: 4.2359, Acc: 0.00%
[2025-04-20 10:08:10]   Batch 180/184: Loss: 3.9546, Acc: 0.00%
[2025-04-20 10:08:10]     Sample 0: True=6, Pred=19
[2025-04-20 10:08:10]     Sample 1: True=29, Pred=34
[2025-04-20 10:14:42] Epoch [1/4], Train Loss: 4.0115, Train Acc: 2.92%, Val Acc: 2.17%
[2025-04-20 10:15:43]   Batch 0/184: Loss: 3.7026, Acc: 0.00%
[2025-04-20 10:15:43]     Sample 0: True=21, Pred=13
[2025-04-20 10:15:43]     Sample 1: True=33, Pred=13
[2025-04-20 10:22:53]   Batch 18/184: Loss: 4.0599, Acc: 0.00%
[2025-04-20 10:29:50]   Batch 36/184: Loss: 4.0503, Acc: 0.00%
[2025-04-20 10:36:49]   Batch 54/184: Loss: 3.9252, Acc: 12.50%
[2025-04-20 10:43:54]   Batch 72/184: Loss: 3.7423, Acc: 6.25%
[2025-04-20 10:51:02]   Batch 90/184: Loss: 4.0488, Acc: 6.25%
[2025-04-20 10:51:02]     Sample 0: True=29, Pred=35
[2025-04-20 10:51:02]     Sample 1: True=16, Pred=35
[2025-04-20 10:57:59]   Batch 108/184: Loss: 3.8206, Acc: 0.00%
[2025-04-20 11:04:57]   Batch 126/184: Loss: 4.5110, Acc: 6.25%
[2025-04-20 11:11:54]   Batch 144/184: Loss: 3.8203, Acc: 0.00%
[2025-04-20 11:18:58]   Batch 162/184: Loss: 3.8084, Acc: 6.25%
[2025-04-20 11:25:57]   Batch 180/184: Loss: 3.8249, Acc: 12.50%
[2025-04-20 11:25:57]     Sample 0: True=3, Pred=3
[2025-04-20 11:25:57]     Sample 1: True=2, Pred=6
[2025-04-20 11:32:27] Epoch [2/4], Train Loss: 3.9074, Train Acc: 2.79%, Val Acc: 2.04%
[2025-04-20 11:33:38]   Batch 0/184: Loss: 3.4564, Acc: 12.50%
[2025-04-20 11:33:38]     Sample 0: True=18, Pred=29
[2025-04-20 11:33:38]     Sample 1: True=9, Pred=31
[2025-04-20 11:40:43]   Batch 18/184: Loss: 3.7765, Acc: 0.00%
[2025-04-20 11:47:40]   Batch 36/184: Loss: 3.8410, Acc: 18.75%
[2025-04-20 11:54:38]   Batch 54/184: Loss: 3.7946, Acc: 0.00%
[2025-04-20 12:02:03]   Batch 72/184: Loss: 3.9074, Acc: 0.00%
[2025-04-20 12:09:18]   Batch 90/184: Loss: 4.1266, Acc: 0.00%
[2025-04-20 12:09:18]     Sample 0: True=23, Pred=14
[2025-04-20 12:09:18]     Sample 1: True=16, Pred=32
[2025-04-20 12:16:34]   Batch 108/184: Loss: 3.8196, Acc: 0.00%
[2025-04-20 12:23:32]   Batch 126/184: Loss: 3.6545, Acc: 0.00%
[2025-04-20 12:30:32]   Batch 144/184: Loss: 3.7173, Acc: 0.00%
[2025-04-20 12:37:25]   Batch 162/184: Loss: 3.5270, Acc: 12.50%
[2025-04-20 12:44:15]   Batch 180/184: Loss: 3.8649, Acc: 0.00%
[2025-04-20 12:44:15]     Sample 0: True=25, Pred=29
[2025-04-20 12:44:15]     Sample 1: True=27, Pred=4
[2025-04-20 12:50:43] Epoch [3/4], Train Loss: 3.8248, Train Acc: 2.82%, Val Acc: 2.04%
[2025-04-20 12:51:58]   Batch 0/184: Loss: 3.7418, Acc: 0.00%
[2025-04-20 12:51:58]     Sample 0: True=7, Pred=32
[2025-04-20 12:51:58]     Sample 1: True=12, Pred=31
[2025-04-20 13:00:04]   Batch 18/184: Loss: 4.0017, Acc: 0.00%
[2025-04-20 13:07:41]   Batch 36/184: Loss: 3.8871, Acc: 6.25%
[2025-04-20 13:14:43]   Batch 54/184: Loss: 3.7323, Acc: 0.00%
[2025-04-20 13:21:49]   Batch 72/184: Loss: 3.6598, Acc: 0.00%
[2025-04-20 13:31:07]   Batch 90/184: Loss: 3.7708, Acc: 0.00%
[2025-04-20 13:31:07]     Sample 0: True=24, Pred=36
[2025-04-20 13:31:07]     Sample 1: True=21, Pred=8
[2025-04-20 13:44:43]   Batch 108/184: Loss: 4.0286, Acc: 0.00%
[2025-04-20 13:55:44]   Batch 126/184: Loss: 3.8776, Acc: 0.00%
[2025-04-20 14:05:52]   Batch 144/184: Loss: 3.8172, Acc: 0.00%
[2025-04-20 14:17:17]   Batch 162/184: Loss: 3.9674, Acc: 0.00%
[2025-04-20 14:26:49]   Batch 180/184: Loss: 3.7344, Acc: 0.00%
[2025-04-20 14:26:49]     Sample 0: True=30, Pred=6
[2025-04-20 14:26:49]     Sample 1: True=30, Pred=14
[2025-04-20 14:37:26] Epoch [4/4], Train Loss: 3.7989, Train Acc: 2.51%, Val Acc: 2.17%
[2025-04-20 14:37:26] Validation Accuracy = 2.17%
[2025-04-20 14:37:26] Dropout Probability Value: 0.25
[2025-04-20 14:39:03]   Batch 0/184: Loss: 4.4333, Acc: 0.00%
[2025-04-20 14:39:03]     Sample 0: True=20, Pred=4
[2025-04-20 14:39:03]     Sample 1: True=13, Pred=12
[2025-04-20 14:53:05]   Batch 18/184: Loss: 4.5434, Acc: 0.00%
[2025-04-20 15:05:50]   Batch 36/184: Loss: 3.9958, Acc: 0.00%
[2025-04-20 15:17:40]   Batch 54/184: Loss: 4.0557, Acc: 0.00%
[2025-04-20 15:29:37]   Batch 72/184: Loss: 3.8382, Acc: 0.00%
[2025-04-20 15:43:33]   Batch 90/184: Loss: 3.8887, Acc: 6.25%
[2025-04-20 15:43:33]     Sample 0: True=3, Pred=31
[2025-04-20 15:43:33]     Sample 1: True=1, Pred=27
[2025-04-20 16:05:14]   Batch 108/184: Loss: 3.7603, Acc: 0.00%
