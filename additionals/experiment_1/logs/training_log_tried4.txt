=== Weakly Supervised Segmentation Pipeline - 2025-04-20 23:16:04.125172 ===

[2025-04-20 23:16:04] Starting weakly supervised segmentation pipeline...
[2025-04-20 23:16:04] Device: cpu
[2025-04-20 23:16:04] PyTorch version: 2.6.0+cpu
[2025-04-20 23:16:04] 
1. Setting up classification datasets...
[2025-04-20 23:16:04] Training set (classification): 2944 images
[2025-04-20 23:16:04] Validation set (classification): 736 images
[2025-04-20 23:16:04] Test set (segmentation): 3669 images
[2025-04-20 23:16:04] 
2. Training the classifier...
[2025-04-20 23:16:04] Dropout Probability Value: 0.1
[2025-04-20 23:17:38]   Batch 0/184: Loss: 3.6235, Acc: 12.50%
[2025-04-20 23:17:38]     Sample 0: True=10, Pred=27
[2025-04-20 23:17:38]     Sample 1: True=24, Pred=23
[2025-04-20 23:30:09]   Batch 18/184: Loss: 3.4784, Acc: 0.00%
[2025-04-20 23:42:40]   Batch 36/184: Loss: 3.8355, Acc: 6.25%
[2025-04-20 23:58:11]   Batch 54/184: Loss: 3.8507, Acc: 0.00%
[2025-04-21 00:19:00]   Batch 72/184: Loss: 4.0756, Acc: 0.00%
[2025-04-21 00:33:44]   Batch 90/184: Loss: 3.7189, Acc: 0.00%
[2025-04-21 00:33:45]     Sample 0: True=25, Pred=35
[2025-04-21 00:33:45]     Sample 1: True=27, Pred=33
[2025-04-21 00:45:57]   Batch 108/184: Loss: 3.5351, Acc: 0.00%
[2025-04-21 00:59:45]   Batch 126/184: Loss: 3.4386, Acc: 6.25%
[2025-04-21 01:11:23]   Batch 144/184: Loss: 3.6939, Acc: 0.00%
[2025-04-21 01:17:57]   Batch 162/184: Loss: 3.7698, Acc: 0.00%
[2025-04-21 01:24:27]   Batch 180/184: Loss: 3.8270, Acc: 0.00%
[2025-04-21 01:24:27]     Sample 0: True=35, Pred=32
[2025-04-21 01:24:27]     Sample 1: True=32, Pred=33
[2025-04-21 01:30:43] Epoch [1/4], Train Loss: 3.7723, Train Acc: 3.02%, Val Acc: 2.17%
[2025-04-21 01:31:52]   Batch 0/184: Loss: 3.7257, Acc: 0.00%
[2025-04-21 01:31:52]     Sample 0: True=26, Pred=18
[2025-04-21 01:31:52]     Sample 1: True=23, Pred=32
[2025-04-21 01:38:31]   Batch 18/184: Loss: 3.5959, Acc: 0.00%
[2025-04-21 01:45:01]   Batch 36/184: Loss: 3.6499, Acc: 0.00%
[2025-04-21 01:51:33]   Batch 54/184: Loss: 3.6775, Acc: 0.00%
[2025-04-21 01:58:08]   Batch 72/184: Loss: 3.8225, Acc: 0.00%
[2025-04-21 02:04:43]   Batch 90/184: Loss: 3.8147, Acc: 0.00%
[2025-04-21 02:04:43]     Sample 0: True=28, Pred=20
[2025-04-21 02:04:43]     Sample 1: True=8, Pred=15
[2025-04-21 02:11:18]   Batch 108/184: Loss: 3.6705, Acc: 6.25%
[2025-04-21 02:17:47]   Batch 126/184: Loss: 3.6672, Acc: 0.00%
[2025-04-21 02:24:17]   Batch 144/184: Loss: 3.6569, Acc: 6.25%
[2025-04-21 02:30:48]   Batch 162/184: Loss: 3.8425, Acc: 0.00%
[2025-04-21 02:37:19]   Batch 180/184: Loss: 4.0159, Acc: 0.00%
[2025-04-21 02:37:19]     Sample 0: True=8, Pred=20
[2025-04-21 02:37:19]     Sample 1: True=7, Pred=28
[2025-04-21 02:43:33] Epoch [2/4], Train Loss: 3.7348, Train Acc: 2.31%, Val Acc: 2.17%
[2025-04-21 02:44:38]   Batch 0/184: Loss: 3.8347, Acc: 0.00%
[2025-04-21 02:44:38]     Sample 0: True=32, Pred=7
[2025-04-21 02:44:38]     Sample 1: True=27, Pred=33
[2025-04-21 02:51:11]   Batch 18/184: Loss: 3.7278, Acc: 6.25%
[2025-04-21 02:57:44]   Batch 36/184: Loss: 3.5785, Acc: 12.50%
[2025-04-21 03:04:15]   Batch 54/184: Loss: 3.6691, Acc: 0.00%
[2025-04-21 03:10:46]   Batch 72/184: Loss: 3.6594, Acc: 0.00%
[2025-04-21 03:17:19]   Batch 90/184: Loss: 3.8465, Acc: 0.00%
[2025-04-21 03:17:19]     Sample 0: True=20, Pred=13
[2025-04-21 03:17:19]     Sample 1: True=18, Pred=28
[2025-04-21 03:23:52]   Batch 108/184: Loss: 3.6190, Acc: 12.50%
[2025-04-21 03:30:27]   Batch 126/184: Loss: 3.5224, Acc: 0.00%
[2025-04-21 03:36:52]   Batch 144/184: Loss: 3.7087, Acc: 0.00%
[2025-04-21 03:43:23]   Batch 162/184: Loss: 3.7646, Acc: 6.25%
[2025-04-21 03:49:56]   Batch 180/184: Loss: 3.5674, Acc: 0.00%
[2025-04-21 03:49:56]     Sample 0: True=13, Pred=6
[2025-04-21 03:49:56]     Sample 1: True=18, Pred=20
[2025-04-21 03:56:10] Epoch [3/4], Train Loss: 3.6994, Train Acc: 2.85%, Val Acc: 2.58%
[2025-04-21 03:57:06]   Batch 0/184: Loss: 3.6344, Acc: 0.00%
[2025-04-21 03:57:06]     Sample 0: True=23, Pred=8
[2025-04-21 03:57:06]     Sample 1: True=12, Pred=33
[2025-04-21 04:03:42]   Batch 18/184: Loss: 3.7441, Acc: 0.00%
[2025-04-21 04:10:15]   Batch 36/184: Loss: 3.6789, Acc: 6.25%
[2025-04-21 04:16:46]   Batch 54/184: Loss: 3.6662, Acc: 18.75%
[2025-04-21 04:23:17]   Batch 72/184: Loss: 3.7551, Acc: 0.00%
[2025-04-21 04:29:52]   Batch 90/184: Loss: 3.8035, Acc: 0.00%
[2025-04-21 04:29:52]     Sample 0: True=5, Pred=34
[2025-04-21 04:29:52]     Sample 1: True=19, Pred=24
[2025-04-21 04:36:20]   Batch 108/184: Loss: 3.9162, Acc: 0.00%
[2025-04-21 04:42:56]   Batch 126/184: Loss: 3.8356, Acc: 6.25%
[2025-04-21 04:49:51]   Batch 144/184: Loss: 3.7737, Acc: 6.25%
[2025-04-21 04:56:40]   Batch 162/184: Loss: 3.7896, Acc: 0.00%
[2025-04-21 05:03:48]   Batch 180/184: Loss: 3.7529, Acc: 0.00%
[2025-04-21 05:03:48]     Sample 0: True=17, Pred=32
[2025-04-21 05:03:48]     Sample 1: True=28, Pred=8
[2025-04-21 05:10:25] Epoch [4/4], Train Loss: 3.6836, Train Acc: 3.16%, Val Acc: 1.77%
[2025-04-21 05:10:26] Validation Accuracy = 2.58%
[2025-04-21 05:10:28] Best Classfier model settings = {'learning_rate': 5e-05, 'weight_decay': 1e-05, 'resnet_prob': 0.1}
